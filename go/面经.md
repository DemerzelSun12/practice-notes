Go 面经

# 一、基础部分

## 1、golang 中 make 和 new 的区别？（基本必问）

共同点：给变量分配内存

不同点：

1) 作用变量类型不同，new给string,int和数组分配内存，make给切片，map，channel分配内存；

2) 返回类型不一样，new返回指向变量的指针，make返回变量本身；

3) new 分配的空间被清零。make 分配空间后，会进行初始化；

4) 字节的面试官还说了另外一个区别，就是分配的位置，在堆上还是在栈上？搜索出来的答案是golang会弱化分配的位置的概念，因为编译的时候会自动内存逃逸处理，懂的大佬帮忙补充下：make、new内存分配是在堆上还是在栈上？

在Go中，栈的内存是由编译器自动进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈（call stack）的简称。一个栈通常又包含了许多栈帧（stack frame），它描述的是函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。

与栈不同的是，应用程序在运行时只会存在一个堆。狭隘地说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过Go的内存分配器分配，并由垃圾收集器回收。

栈是每个goroutine独有的，这就意味着栈上的内存操作是不需要加锁的。而堆上的内存，有时需要加锁防止多线程冲突（为什么要说有时呢，因为Go的内存分配策略学习了TCMalloc的线程缓存思想，他为每个处理器P分配了一个mcache，从mcache分配内存也是无锁的）。

而且，对于程序堆上的内存回收，还需要通过标记清除阶段，例如Go采用的三色标记法。但是，在栈上的内存而言，它的分配与释放非常廉价。简单地说，它只需要两个CPU指令：一个是分配入栈，另外一个是栈内释放。而这，只需要借助于栈相关寄存器即可完成。

另外还有一点，栈内存能更好地利用CPU的缓存策略。因为它们相较于堆而言是更连续的。

如果可以，Go编译器会尽可能将变量分配到到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针（dangling pointer）。另外，如果局部变量非常大，也会将其分配在堆上。

那么，Go是如何确定的呢？答案就是：逃逸分析。编译器通过逃逸分析技术去选择堆或者栈，逃逸分析的基本思想如下：**检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是所谓的逃逸，必须在堆上进行分配。**

Go语言虽然没有明确说明逃逸分析规则，但是有以下几点准则，是可以参考的。

- 逃逸分析是在编译器完成的，这是不同于jvm的运行时逃逸分析;
- 如果变量在函数外部没有引用，则优先放到栈中；
- 如果变量在函数外部存在引用，则必定放在堆中；

可通过go build -gcflags '-m -l'命令来查看逃逸分析结果，其中-m 打印逃逸分析信息，-l禁止内联优化。

核心思想：

**尽量写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。**

所以，会发现有些Go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态地在堆上分配内存少的多。当然该做法不是绝对的，如果结构体较大，传递指针将更合适。


## 2、数组和切片的区别 （基本必问）
相同点：

1) 只能存储一组相同类型的数据结构

2) 都是通过下标来访问，并且有容量长度，长度通过 len 获取，容量通过 cap 获取

区别：

1）数组是定长，访问和复制不能超过数组定义的长度，否则就会下标越界，切片长度和容量可以自动扩容

2）数组是值类型，切片是引用类型，每个切片都引用了一个底层数组，切片本身不能存储任何数据，都是这底层数组存储数据，所以修改切片的时候修改的是底层数组中的数据。切片一旦扩容，指向一个新的底层数组，内存地址也就随之改变

简洁的回答：

1）定义方式不一样 2）初始化方式不一样，数组需要指定大小，大小不改变 3）在函数传递中，数组切片都是值传递。

数组的定义

```go
var a1 [3]int

var a2 [...]int{1,2,3}
```
切片的定义
```go
var a1 []int

var a2 :=make([]int,3,5)
```
数组的初始化
```go
a1 := [...]int{1,2,3}

a2 := [5]int{1,2,3}
```
切片的初始化
```go
b:= make([]int,3,5)
```

## 3、for range 的时候它的地址会发生变化么？
答：在 for a,b := range c 遍历中， a 和 b 在内存中只会存在一份，即之后每次循环时遍历到的数据都是以值覆盖的方式赋给 a 和 b，a，b 的内存地址始终不变。由于有这个特性，for 循环里面如果开协程，不要直接把 a 或者 b 的地址传给协程。解决办法：在每次循环时，创建一个临时变量。

## 4、go defer，多个 defer 的顺序，defer 在什么时机会修改返回值？
作用：defer延迟函数，释放资源，收尾工作；如释放锁，关闭文件，关闭链接；捕获panic;

避坑指南：defer函数紧跟在资源打开后面，否则defer可能得不到执行，导致内存泄露。

多个 defer 调用顺序是 LIFO（后入先出），defer后的操作可以理解为压入栈中

defer，return，return value（函数返回值） 执行顺序：先进行返回值赋值，再执行 defer，最后执行 return 指令。


## 5、uint 类型溢出问题

超过最大存储值如uint8最大是255

var a uint8 =255

var b uint8 =1

a+b = 0总之类型溢出会出现难以意料的事

## 6、能介绍下 rune 类型吗？

相当int32

golang中的字符串底层实现是通过byte数组的，中文字符在unicode下占2个字节，在utf-8编码下占3个字节，而golang默认编码正好是utf-8

byte 等同于int8，常用来处理ascii字符

rune 等同于int32,常用来处理unicode或utf-8字符

## 7、 golang 中解析 tag 是怎么实现的？反射原理是什么？(中高级肯定会问，比较难，需要自己多去总结)

```go
type User struct {
	name string `json:name-field`
	age  int
}
func main() {
	user := &User{"John Doe The Fourth", 20}

	field, ok := reflect.TypeOf(user).Elem().FieldByName("name")
	if !ok {
		panic("Field not found")
	}
	fmt.Println(getStructTag(field))
}

func getStructTag(f reflect.StructField) string {
	return string(f.Tag)
}
```

Go 中解析的 tag 是通过反射实现的，反射是指计算机程序在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力或动态知道给定数据对象的类型和结构，并有机会修改它。反射将接口变量转换成反射对象 Type 和 Value；反射可以通过反射对象 Value 还原成原先的接口变量；反射可以用来修改一个变量的值，前提是这个值可以被修改；tag是啥:结构体支持标记，name string `json:name-field` 就是 `json:name-field` 这部分

gorm json yaml gRPC protobuf gin.Bind()都是通过反射来实现的

## 8、调用函数传入结构体时，应该传值还是指针？ （Golang 都是传值）

Go 的函数参数传递都是值传递。所谓值传递：指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。参数传递还有引用传递，所谓引用传递是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数

因为 Go 里面的 map，slice，chan 是引用类型。变量区分值类型和引用类型。所谓值类型：变量和变量的值存在同一个位置。所谓引用类型：变量和变量的值是不同的位置，变量的值存储的是对值的引用。但并不是 map，slice，chan 的所有的变量在函数内都能被修改，不同数据类型的底层存储结构和实现可能不太一样，情况也就不一样。

## 9、讲讲 Go 的 slice 底层数据结构和一些特性？
答：Go 的 slice 底层数据结构是由一个 array 指针指向底层数组，len 表示切片长度，cap 表示切片容量。slice 的主要实现是扩容。对于 append 向 slice 添加元素时，假如 slice 容量够用，则追加新元素进去，slice.len++，返回原来的 slice。当原容量不够，则 slice 先扩容，扩容之后 slice 得到新的 slice，将元素追加进新的 slice，slice.len++，返回新的 slice。对于切片的扩容规则：当切片比较小时（容量小于 1024），则采用较大的扩容倍速进行扩容（新的扩容会是原来的 2 倍），避免频繁扩容，从而减少内存分配的次数和数据拷贝的代价。当切片较大的时（原来的 slice 的容量大于或者等于 1024），采用较小的扩容倍速（新的扩容将扩大大于或者等于原来 1.25 倍），主要避免空间浪费，网上其实很多总结的是 1.25 倍，那是在不考虑内存对齐的情况下，实际上还要考虑内存对齐，扩容是大于或者等于 1.25 倍。

（关于刚才问的 slice 为什么传到函数内可能被修改，如果 slice 在函数内没有出现扩容，函数外和函数内 slice 变量指向是同一个数组，则函数内复制的 slice 变量值出现更改，函数外这个 slice 变量值也会被修改。如果 slice 在函数内出现扩容，则函数内变量的值会新生成一个数组（也就是新的 slice，而函数外的 slice 指向的还是原来的 slice，则函数内的修改不会影响函数外的 slice。）

## 10、讲讲 Go 的 select 底层数据结构和一些特性？（难点，没有项目经常可能说不清，面试一般会问你项目中怎么使用select）
答：go 的 select 为 golang 提供了多路 IO 复用机制，和其他 IO 复用一样，用于检测是否有读写事件是否 ready。linux 的系统 IO 模型有 select，poll，epoll，go 的 select 和 linux 系统 select 非常相似。

select 结构组成主要是由 case 语句和执行的函数组成 select 实现的多路复用是：每个线程或者进程都先到注册和接受的 channel（装置）注册，然后阻塞，然后只有一个线程在运输，当注册的线程和进程准备好数据后，装置会根据注册的信息得到相应的数据。

select 的特性

1) select 操作至少要有一个 case 语句，出现读写 nil 的 channel 该分支会忽略，在 nil 的 channel 上操作则会报错。

2) select 仅支持管道，而且是单协程操作。

3) 每个 case 语句仅能处理一个管道，要么读要么写。

4) 多个 case 语句的执行顺序是随机的。

5) 存在 default 语句，select 将不会阻塞，但是存在 default 会影响性能。

## 11、讲讲 Go 的 defer 底层数据结构和一些特性？
答：每个 defer 语句都对应一个_defer 实例，多个实例使用指针连接起来形成一个单连表，保存在 gotoutine 数据结构中，每次插入_defer 实例，均插入到链表的头部，函数结束再一次从头部取出，从而形成后进先出的效果。

defer 的规则总结：

延迟函数的参数是 defer 语句出现的时候就已经确定了的。

延迟函数执行按照后进先出的顺序执行，即先出现的 defer 最后执行。

延迟函数可能操作主函数的返回值。

申请资源后立即使用 defer 关闭资源是个好习惯。

## 12、单引号，双引号，反引号的区别？
单引号，表示byte类型或rune类型，对应 uint8和int32类型，默认是 rune 类型。byte用来强调数据是raw data，而不是数字；而rune用来表示Unicode的code point。

双引号，才是字符串，实际上是字符数组。可以用索引号访问某字节，也可以用len()函数来获取字符串所占的字节长度。

反引号，表示字符串字面量，但不支持任何转义序列。字面量 raw literal string 的意思是，你定义时写的啥样，它就啥样，你有换行，它就换行。你写转义字符，它也就展示转义字符。


# 二、map相关

## 1、map 使用注意的点，是否并发安全？

map的类型是map[key]，key类型的key必须是可比较的，通常情况，会选择内建的基本类型，比如整数、字符串做key的类型。如果要使用struct作为key，要保证struct对象在逻辑上是不可变的。在Go语言中，map[key]函数返回结果可以是一个值，也可以是两个值。map是无序的，如果我们想要保证遍历map时元素有序，可以使用辅助的数据结构，例如orderedmap。

第一，一定要先初始化，否则panic

第二，map类型是容易发生并发访问问题的。不注意就容易发生程序运行时并发读写导致的panic。 Go语言内建的map对象不是线程安全的，并发读写的时候运行时会有检查，遇到并发问题就会导致panic。

## 2、map 循环是有序的还是无序的？
无序的, map 因扩张⽽重新哈希时，各键值项存储位置都可能会发生改变，顺序自然也没法保证了，所以官方避免大家依赖顺序，直接打乱处理。就是 for range map 在开始处理循环逻辑的时候，就做了随机播种

## 3、 map 中删除一个 key，它的内存会释放么？（常问）
如果删除的元素是值类型，如int，float，bool，string以及数组和struct，map的内存不会自动释放

如果删除的元素是引用类型，如指针，slice，map，chan等，map的内存会自动释放，但释放的内存是子元素应用类型的内存占用

将map设置为nil后，内存被回收。

## 4、怎么处理对 map 进行并发访问？有没有其他方案？ 区别是什么？

1. 使用读写锁：

通过使用sync.Mutex锁或sync.RWMutex读写锁来保证同一时刻只有一个goroutine对map进行读写。例如：

```go
import (
  "sync"
)
​
var m sync.RWMutex
var data = make(map[string]int)
​
func readData(key string) int {
  m.RLock()
  defer m.RUnlock()
  return data[key]
}
​
func writeData(key string, value int) {
  m.Lock()
  defer m.Unlock()
  data[key] = value
}
​
```

2. 使用内置的sync.Map

sync.Map是一个并发安全的map实现，与普通map不同，它不需要加锁就可以进行读写操作，因此可以减少死锁的风险。

使用方法如下：

创建一个sync.Map对象：
```go
goCopy code
m := sync.Map{}
```

设置键值对：
```go
goCopy code
m.Store("key", "value")
```

获取键的值：
```go
goCopy code
val, ok := m.Load("key")
if ok {
    // Key is present
} else {
    // Key is absent
}
```

删除键值对：
```go
goCopy code
m.Delete("key")
```

遍历键值对：
```go
goCopy code
m.Range(func(key, value interface{}) bool {
    // Do something with key and value
    return true
})
```
这是使用sync.Map的简单示例。它是并发安全的，因此可以支持多个协程的并发访问。

### 区别

压测结果
1）写入：

在写入元素上，最慢的是 sync.map 类型，其次是原生 map+互斥锁（Mutex），最快的是原生 map+读写锁（RwMutex）。

总体的排序（从慢到快）为：SyncMapStore < MapStore < RwMapStore。

2）查找：

在查找元素上，最慢的是原生 map+互斥锁，其次是原生 map+读写锁。最快的是 sync.map 类型。

总体的排序为：MapLookup < RwMapLookup < SyncMapLookup。

3）删除：

在删除元素上，最慢的是原生 map+读写锁，其次是原生 map+互斥锁，最快的是 sync.map 类型。

总体的排序为：RwMapDelete < MapDelete < SyncMapDelete。

场景分析
根据上述的压测结果，我们可以得出 sync.Map 类型：

在读和删场景上的性能是最佳的，领先一倍有多。
在写入场景上的性能非常差，落后原生 map+锁整整有一倍之多。
因此在实际的业务场景中。假设是读多写少的场景，会更建议使用 sync.Map 类型。

但若是那种写多的场景，例如多 goroutine 批量的循环写入，那就建议另辟途径了，性能不忍直视（无性能要求另当别论）。


### 原因

当我们从 sync.Map 类型中读取数据时，其会先查看 read 中是否包含所需的元素：

若有，则通过 atomic 原子操作读取数据并返回。
若无，则会判断 read.readOnly 中的 amended 属性，他会告诉程序 dirty 是否包含 read.readOnly.m 中没有的数据；因此若存在，也就是 amended 为 true，将会进一步到 dirty 中查找数据。
sync.Map 的读操作性能如此之高的原因，就在于存在 read 这一巧妙的设计，其作为一个缓存层，提供了快路径（fast path）的查找。

写入过程的整体流程就是：

- 查 read，read 上没有，或者已标记删除状态。
- 上互斥锁（Mutex）。
- 操作 dirty，根据各种数据情况和状态进行处理。

回到最初的话题，为什么他写入性能差那么多。究其原因：

写入一定要会经过 read，无论如何都比别人多一层，后续还要查数据情况和状态，性能开销相较更大。
（第三个处理分支）当初始化或者 dirty 被提升后，会从 read 中复制全量的数据，若 read 中数据量大，则会影响性能。
可得知 sync.Map 类型不适合写多的场景，读多写少是比较好的。

若有大数据量的场景，则需要考虑 read 复制数据时的偶然性能抖动是否能够接受。


## 5、 nil map 和空 map 有何不同？

1) 可以对未初始化的map进行取值，但取出来的东西是空：

```go
var m1 map[string]string

fmt.Println(m1["1"])
```


2) 不能对未初始化的map进行赋值，这样将会抛出一个异常：

```go
var m1 map[string]string

m1["1"] = "1"

panic: assignment to entry in nil map
```

3) 通过fmt打印map时，空map和nil map结果是一样的，都为map[]。所以，这个时候别断定map是空还是nil，而应该通过map == nil来判断。

nil map 未初始化，空map是长度为空

## 6、map 的数据结构是什么？是怎么实现扩容？

答：golang 中 map 是一个 kv 对集合。底层使用 hash table，用链表来解决冲突 ，出现冲突时，不是每一个 key 都申请一个结构通过链表串起来，而是以 bmap 为最小粒度挂载，一个 bmap 可以放 8 个 kv。在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。每个 map 的底层结构是 hmap，是有若干个结构为 bmap 的 bucket 组成的数组。每个 bucket 底层都采用链表结构。


## 7、slices能作为map类型的key吗？

其实是这个问题的变种：golang 哪些类型可以作为map key？

答案是：在golang规范中，可比较的类型都可以作为map key；这个问题又延伸到在：golang规范中，哪些数据类型可以比较？

不能作为map key 的类型包括：

slices
maps
functions


# 三、context 相关

## 1、context 结构是什么样的？context 使用场景和用途？
（难，也常常问你项目中怎么用，光靠记答案很难让面试官满意，反正有各种结合实际的问题）

答：Go 的 Context 的数据结构包含 Deadline，Done，Err，Value，Deadline 方法返回一个 time.Time，表示当前 Context 应该结束的时间，ok 则表示有结束时间，Done 方法当 Context 被取消或者超时时候返回的一个 close 的 channel，告诉给 context 相关的函数要停止当前工作然后返回了，Err 表示 context 被取消的原因，Value 方法表示 context 实现共享数据存储的地方，是协程安全的。context 在业务中是经常被使用的，

其主要的应用 ：

1. 上下文控制
2. 多个 goroutine 之间的数据交互等
3. 超时控制：到某个时间点超时，过多久超时。


# 四、 channel相关

## 1. channel 是否线程安全？锁用在什么地方？

线程安全的，channel的度层实现中，hchan结构体中采用Mutex锁保证数据读写安全。在循环数组buff中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据


## 2. go channel 的底层实现原理 （数据结构）

channel是golang中用来实现多个goroutine通信的管道，它的底层是一个叫做hchan的结构体。在go的runtime包下。

总结hchan结构体的主要组成部分有四个：

- 用来保存goroutine之间传递数据的循环链表。=====> buf。
- 用来记录此循环链表当前发送或接收数据的下标值。=====> sendx和recvx。
- 用于保存向该chan发送和从改chan接收数据的goroutine的队列。=====> sendq 和 recvq
- 保证channel写入和读取数据时线程安全的锁。 =====> lock

思想：底层是通过hchan结构体的buf，并使用copy内存的方式进行通信，最后达到了共享内存的目的，这里也体现了Go中的CSP并发模型。

Go中的CSP并发模型即是通过goroutine和channel实现的。

CSP并发模型：不要以共享内存的方式来通信，相反，要通过通信的方式来共享内存。

## 3. nil、关闭的 channel、有数据的 channel，再进行读、写、关闭会怎么样？（各类变种题型，重要）

channel有两种类型：有缓冲和无缓冲

三种模式：写操作模式（单向通道）、读操作模式（单向通道）、读写操作（双向通道）

三种状态：

||未初始化|关闭|正常|
|:--:|:--:|:--:|:--:|
|关闭|panic|painc|正常关闭|
|发送|永远阻塞导致死锁|panic|阻塞或者成功发送|
|接收|永远阻塞导致死锁|缓冲区为空则为零值，否则可以继续读|阻塞或者成功接收|

注意点：
- 一个channel不能多次关闭，否则panic
- 如果一个channel被多个goroutine监听，则channel上数据可能被任意一个goroutine取走并消费
- 如果一个channel被多个goroutine监听，若channel关闭，则所有goroutine都可接收到退出信号

## 4、向 channel 发送数据和从 channel 读数据的流程是什么样的？

发送流程：




## 5、讲讲 Go 的 chan 底层数据结构和主要使用场景

答：channel 的数据结构包含 qccount 当前队列中剩余元素个数，dataqsiz 环形队列长度，即可以存放的元素个数，buf 环形队列指针，elemsize 每个元素的大小，closed 标识关闭状态，elemtype 元素类型，sendx 队列下表，指示元素写入时存放到队列中的位置，recv 队列下表，指示元素从队列的该位置读出。recvq 等待读消息的 goroutine 队列，sendq 等待写消息的 goroutine 队列，lock 互斥锁，chan 不允许并发读写。

**无缓冲和有缓冲区别：** 管道没有缓冲区，从管道读数据会阻塞，直到有协程向管道中写入数据。同样，向管道写入数据也会阻塞，直到有协程从管道读取数据。管道有缓冲区但缓冲区没有数据，从管道读取数据也会阻塞，直到协程写入数据，如果管道满了，写数据也会阻塞，直到协程从缓冲区读取数据。

**channel 的一些特点** 
1）、读写值 nil 管道会永久阻塞 
2）、关闭的管道读数据仍然可以读数据 
3）、往关闭的管道写数据会 panic 
4）、关闭为 nil 的管道 panic 
5）、关闭已经关闭的管道 panic

**向 channel 写数据的流程**： 如果等待接收队列 recvq 不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从 recvq 取出 G,并把数据写入，最后把该 G 唤醒，结束发送过程； 如果缓冲区中有空余位置，将数据写入缓冲区，结束发送过程； 如果缓冲区中没有空余位置，将待发送数据写入 G，将当前 G 加入 sendq，进入睡眠，等待被读 goroutine 唤醒；

**向 channel 读数据的流程**： 如果等待发送队列 sendq 不为空，且没有缓冲区，直接从 sendq 中取出 G，把 G 中数据读出，最后把 G 唤醒，结束读取过程； 如果等待发送队列 sendq 不为空，此时说明缓冲区已满，从缓冲区中首部读出数据，把 G 中数据写入缓冲区尾部，把 G 唤醒，结束读取过程； 如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程；将当前 goroutine 加入 recvq，进入睡眠，等待被写 goroutine 唤醒；

使用场景： 消息传递、消息过滤，信号广播，事件订阅与广播，请求、响应转发，任务分发，结果汇总，并发控制，限流，同步与异步


# 五、GMP相关

## 1、什么是 GMP？（必问）

G（Goroutine）：我们所说的协程，为⽤户级的轻量级线程，每个 Goroutine 对象中的 sched 保存着其上下⽂信息。
M（Machine）：对内核级线程的封装，数量对应真实的 CPU数（真正⼲活的对象）。
P（Processor）：即为 G和 M的调度对象，⽤来调度 G和 M之间的关联关系，其数量可通过 GOMAXPROCS()来设置，默认为核⼼数。

### 调度流程

- 每个 P 有个局部队列，局部队列保存待执⾏的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就会把 goroutine 放到全局队列
- 每个 P和⼀个 M绑定，M是真正的执⾏ P中 goroutine 的实体，M 从绑定的 P中的局部队列获取 G来执⾏
- 当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执⾏G。
- 当从全局队列中没有获取到可执⾏的G时候，M会从其他 P 的局部队列中偷取 G来执⾏，这种从其他 P偷的⽅式称为 work stealing 
- 当 G 因系统调⽤(syscall)阻塞时会阻塞 M，此时P会和M解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M就会新建⼀个 M。
- 当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G；当阻塞的 G恢复后会重新进⼊ runnable 进⼊ P队列等待执⾏。

### GMP 中 work stealing 机制 

存到 P本地队列或者是全局队列。P此时去唤醒⼀个 M。P继续执⾏它的执⾏序。M寻找是否有空闲的 P，如果有则将该 G对象移动到它本身。接下来 M执⾏⼀个调度循环(调⽤ G对象->执⾏->清理线程→继续找新的 Goroutine 执⾏)。

### GMP 中 hand off 机制 

当本线程 M因为 G进⾏的系统调⽤阻塞时，线程释放绑定的 P，把 P转移给其他空闲的 M'执⾏。当发⽣上线⽂切换时，需要对执⾏现场进⾏保护，以便下次被调度执⾏时进⾏现场恢复。Go调度器 M的栈保存在 G对象上，只需要将 M所需要的寄存器(SP、PC等)保存到 G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下⽂切换了，在中断之前把现场保存起来。如果此时 G任务还没有执⾏完，M可以将任务重新丢到 P的任务队列，等待下⼀次被调度执⾏。当再次被调度执⾏时，M通过访问 G的 vdsoSP、vdsoPC寄存器进⾏现场恢复(从上次中断位置继续执⾏)。



## 2、进程、线程、协程有什么区别？（必问）

进程：是应用程序的启动实例，是系统进⾏资源分配和调度的⼀个独⽴单位。每个进程都有⾃⼰的独⽴内存空间，不同进程通过进程间通信来通信。由于进程⽐较重量，占据独⽴的内存，所以上下⽂进程间的切换开销（栈、寄存器、虚拟内存、⽂件句柄等）⽐较⼤，但相对⽐较稳定安全。

线程：线程是进程的⼀个实体，是CPU调度和分派的基本单位，它是⽐进程更⼩的能独⽴运⾏的基本单位.线程⾃⼰基本上不拥有系统资源，只拥有⼀点在运⾏中必不可少的资源(如程序计数器，⼀组寄存器和栈)，但是它可与同属⼀个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下⽂切换很快，资源开销较少，但相⽐进程不够稳定容易丢失数据。

协程：协程是⼀种⽤户态的轻量级线程，协程的调度完全由⽤户控制。协程拥有⾃⼰的寄存器上下⽂和栈。协程调度切换时，将寄存器上下⽂和栈保存到其他地⽅，在切回来的时候，恢复先前保存的寄存器上下⽂和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下⽂的切换⾮常快。

## 3、抢占式调度是如何抢占的？

基于协作式抢占

基于信号量抢占

就像操作系统要负责线程的调度一样，Go的runtime要负责goroutine的调度。现代操作系统调度线程都是抢占式的，我们不能依赖用户代码主动让出CPU，或者因为IO、锁等待而让出，这样会造成调度的不公平。基于经典的时间片算法，当线程的时间片用完之后，会被时钟中断给打断，调度器会将当前线程的执行上下文进行保存，然后恢复下一个线程的上下文，分配新的时间片令其开始执行。这种抢占对于线程本身是无感知的，系统底层支持，不需要开发人员特殊处理。

基于时间片的抢占式调度有个明显的优点，能够避免CPU资源持续被少数线程占用，从而使其他线程长时间处于饥饿状态。goroutine的调度器也用到了时间片算法，但是和操作系统的线程调度还是有些区别的，因为整个Go程序都是运行在用户态的，所以不能像操作系统那样利用时钟中断来打断运行中的goroutine。也得益于完全在用户态实现，goroutine的调度切换更加轻量。

上面这两段文字只是对调度的一个概括，具体的协作式调度、信号量调度大家还需要去详细了解，这偏底层了，大厂或者中高级开发会问。（字节就问了）

## 4、M 和 P 的数量问题？

p默认cpu内核数

M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来

【Go语言调度模型G、M、P的数量多少合适？】

## 5. CSP 模型

CSP模型是上个世纪七⼗年代提出的,**不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的⽅式来共享内存”**。⽤于描述两个独⽴的并发实体通过共享的通讯 channel(管道)进⾏通信的并发模型。 CSP中channel是第⼀类对象，它不关注发送消息的实体，⽽关注与发送消息时使⽤的channel。

Golang中 channel 是被单独创建并且可以在进程之间传递，它的通信模式类似于 boss-worker 模式的，⼀个实体通过将消息发送到channel 中，然后⼜监听这个 channel 的实体处理，两个实体之间是匿名的，这个就实现实体中间的解耦，其中 channel 是同步的⼀个消息被发送到 channel 中，最终是⼀定要被另外的实体消费掉的，在实现原理上其实类似⼀个阻塞的消息队列。

Goroutine 是Golang实际并发执⾏的实体，它底层是使⽤协程(coroutine)实现并发，coroutine是⼀种运⾏在⽤户态的⽤户线程，类似于 greenthread，go底层选择使⽤coroutine的出发点是因为，它具有以下特点：

- ⽤户空间 避免了内核态和⽤户态的切换导致的成本。
- 可以由语⾔和框架层进⾏调度。
- 更⼩的栈空间允许创建⼤量的实例。




# 六、锁相关

## 1、除了 mutex 以外还有那些方式安全读写共享变量？

* 将共享变量的读写放到一个 goroutine 中，其它 goroutine 通过 channel 进行读写操作。

* 可以用个数为 1 的信号量（semaphore）实现互斥

* 通过 Mutex 锁实现

## 2、Go 如何实现原子操作？

答：原子操作就是不可中断的操作，外界是看不到原子操作的中间状态，要么看到原子操作已经完成，要么看到原子操作已经结束。在某个值的原子操作执行的过程中，CPU 绝对不会再去执行其他针对该值的操作，那么其他操作也是原子操作。

Go 语言的标准库代码包 sync/atomic 提供了原子的读取（Load 为前缀的函数）或写入（Store 为前缀的函数）某个值（这里细节还要多去查查资料）。

原子操作与互斥锁的区别

1) 互斥锁是一种数据结构，用来让一个线程执行程序的关键部分，完成互斥的多个操作。
2) 原子操作是针对某个值的单个互斥操作。
3) Mutex 是悲观锁还是乐观锁？悲观锁、乐观锁是什么？

### 悲观锁

悲观锁：当要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观并发控制【Pessimistic Concurrency Control，缩写“PCC”，又名“悲观锁”】。

### 乐观锁

乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果冲突，则返回给用户异常信息，让用户决定如何去做。乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量

## 4、Mutex 有几种模式？

1) 正常模式

当前的mutex只有一个goruntine来获取，那么没有竞争，直接返回。
新的goruntine进来，如果当前mutex已经被获取了，则该goruntine进入一个先入先出的waiter队列，在mutex被释放后，waiter按照先进先出的方式获取锁。该goruntine会处于自旋状态(不挂起，继续占有cpu)。
新的goruntine进来，mutex处于空闲状态，将参与竞争。新来的 goroutine 有先天的优势，它们正在 CPU 中运行，可能它们的数量还不少，所以，在高并发情况下，被唤醒的 waiter 可能比较悲剧地获取不到锁，这时，它会被插入到队列的前面。如果 waiter 获取不到锁的时间超过阈值 1 毫秒，那么，这个 Mutex 就进入到了饥饿模式。

2) 饥饿模式

在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine 不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin（自旋），它会乖乖地加入到等待队列的尾部。 如果拥有 Mutex 的 waiter 发现下面两种情况的其中之一，它就会把这个 Mutex 转换成正常模式:

此 waiter 已经是队列中的最后一个 waiter 了，没有其它的等待锁的 goroutine 了；
此 waiter 的等待时间小于 1 毫秒。
5、goroutine 的自旋占用资源如何解决
自旋锁是指当一个线程在获取锁的时候，如果锁已经被其他线程获取，那么该线程将循环等待，然后不断地判断是否能够被成功获取，直到获取到锁才会退出循环。

自旋的条件如下：

1）还没自旋超过 4 次,

2）多核处理器，

3）GOMAXPROCS > 1，

4）p 上本地 goroutine 队列为空。

mutex 会让当前的 goroutine 去空转 CPU，在空转完后再次调用 CAS 方法去尝试性的占有锁资源，直到不满足自旋条件，则最终会加入到等待队列里。


# 七、并发相关

## 1、怎么控制并发数？
第一，有缓冲通道

根据通道中没有数据时读取操作陷入阻塞和通道已满时继续写入操作陷入阻塞的特性，正好实现控制并发数量。

```go
func main() {
	count := 10 // 最大支持并发
	sum := 100 // 任务总数
	wg := sync.WaitGroup{} //控制主协程等待所有子协程执行完之后再退出。

	c := make(chan struct{}, count) // 控制任务并发的chan
	defer close(c)

	for i:=0; i<sum;i++{
		wg.Add(1)
		c <- struct{}{} // 作用类似于waitgroup.Add(1)
		go func(j int) {
			defer wg.Done()
			fmt.Println(j)
			<- c // 执行完毕，释放资源
		}(i)
	}
	wg.Wait()
}
```

第二，三方库实现的协程池

panjf2000/ants（比较火）

Jeffail/tunny

```go
import (
	"log"
	"time"

	"github.com/Jeffail/tunny"
)
func main() {
	pool := tunny.NewFunc(10, func(i interface{}) interface{} {
		log.Println(i)
		time.Sleep(time.Second)
		return nil
	})
	defer pool.Close()

	for i := 0; i < 500; i++ {
		go pool.Process(i)
	}
	time.Sleep(time.Second * 4)
}
```

## 2、多个 goroutine 对同一个 map 写会 panic，异常是否可以用 defer 捕获？

可以捕获异常，但是只能捕获一次，Go语言，可以使用多值返回来返回错误。不要用异常代替错误，更不要用来控制流程。在极个别的情况下，才使用Go中引入的Exception处理：defer, panic, recover Go中，对异常处理的原则是：多用error包，少用panic

```go
defer func() {
		if err := recover(); err != nil {
			// 打印异常，关闭资源，退出此函数
			fmt.Println(err)
		}
	}()
```

## 3、如何优雅的实现一个 goroutine 池
（百度、手写代码，本人面传音控股被问道：请求数大于消费能力怎么设计协程池）

是保证高并发系统稳定性、高可用的核心部分之一。

ants是一个受fasthttp启发的高性能协程池，fasthttp号称是比go原生的net/http快10倍，其原因之一就是采用了各种池化技术， ants相比之前两种协程池，其模型更像是之前接触到的数据库连接池，需要从空余的worker中取出一个来执行任务, 当无可用空余worker的时候再去创建，而当pool的容量达到上线之后，剩余的任务阻塞等待当前进行中的worker执行完毕将worker放回pool, 直至pool中有空闲worker。 ants在内存的管理上做得很好，除了定期清除过期worker(一定时间内没有分配到任务的worker)，ants还实现了一种适用于大批量相同任务的pool, 这种pool与一个需要大批量重复执行的函数锁绑定，避免了调用方不停的创建，更加节省内存。

```go
package main
 
import (
	"fmt"
	"github.com/panjf2000/ants"
	"sync"
	"time"
)
 
//任务
func sendMail(i int, wg *sync.WaitGroup) func() {
	var cnt int
	return func() {
		for {
			time.Sleep(time.Second * 2)
			fmt.Println("send mail to ", i)
			cnt++
			if cnt > 5 && i == 1 {
				fmt.Println("退出协程ID:", i)
				break
			}
		}
		wg.Done()
	}
}
 
func main() {
	wg := sync.WaitGroup{}
 
	//申请一个协程池对象
	pool, _ := ants.NewPool(2)
 
	//关闭协程池
	defer pool.Release()
 
	// 向pool提交任务
	for i := 1; i <= 5; i++ {
		pool.Submit(sendMail(i, &wg))
		wg.Add(1)
	}
	wg.Wait()
}
```

# 八、GC相关

## 1、go gc 是怎么实现的？（必问）
答：

细分常见的三个问题：1、GC机制随着golang版本变化如何变化的？2、三色标记法的流程？3、插入屏障、删除屏障，混合写屏障（具体的实现比较难描述，但你要知道屏障的作用：避免程序运行过程中，变量被误回收；减少STW的时间）4、虾皮还问了个开放性的题目：你觉得以后GC机制会怎么优化？

Go 的 GC 回收有三次演进过程，Go V1.3 之前普通标记清除（mark and sweep）方法，整体过程需要启动 STW，效率极低。GoV1.5 三色标记法，堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要 STW)，效率普通。GoV1.8 三色标记法，混合写屏障机制：栈空间不启动（全部标记成黑色），堆空间启用写屏障，整个过程不要 STW，效率高。

Go1.3 之前的版本所谓标记清除是先启动 STW 暂停，然后执行标记，再执行数据回收，最后停止 STW。Go1.3 版本标记清除做了点优化，流程是：先启动 STW 暂停，然后执行标记，停止 STW，最后再执行数据回收。

### 三色标记法

Go1.5 三色标记主要是插入屏障和删除屏障，写入屏障的流程：

程序开始，全部标记为白色，
1）所有的对象放到白色集合，
2）遍历一次根节点，得到灰色节点，
3）遍历灰色节点，将可达的对象，从白色标记灰色，遍历之后的灰色标记成黑色，
4）由于并发特性，此刻外界向在堆中的对象发生添加对象，以及在栈中的对象添加对象，**在堆中的对象会触发插入屏障机制，栈中的对象不触发，**
5）由于堆中对象插入屏障，则会把堆中黑色对象添加的白色对象改成灰色，栈中的黑色对象添加的白色对象依然是白色，
6）循环第 5 步，直到没有灰色节点，
7）在准备回收白色前，重新遍历扫描一次栈空间，加上 STW 暂停保护栈，防止外界干扰（有新的白色会被添加成黑色）在 STW 中，将栈中的对象一次三色标记，直到没有灰色，
8）停止 STW，清除白色。至于删除写屏障，则是遍历灰色节点的时候出现可达的节点被删除，这个时候触发删除写屏障，这个可达的被删除的节点也是灰色，等循环三色标记之后，直到没有灰色节点，然后清理白色，删除写屏障会造成一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉。

### GoV1.8 混合写屏障规则是：

1）GC 开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需 STW)，
2）GC 期间，任何在栈上创建的新对象，均为黑色。
3）被删除的对象标记为灰色。
4）被添加的对象标记为灰色。


## 2、go 是 gc 算法是怎么实现的？ （得物，出现频率低）

```go
func GC() {
	n := atomic.Load(&amp;work.cycles)
	gcWaitOnMark(n)

	gcStart(gcTrigger{kind: gcTriggerCycle, n: n + 1})
	gcWaitOnMark(n + 1)

	for atomic.Load(&amp;work.cycles) == n+1 &amp;&amp; sweepone() != ^uintptr(0) {
		sweep.nbgsweep++
		Gosched()
	}
	for atomic.Load(&amp;work.cycles) == n+1 &amp;&amp; atomic.Load(&amp;mheap_.sweepers) != 0 {
		Gosched()
	}
	mp := acquirem()
	cycle := atomic.Load(&amp;work.cycles)
	if cycle == n+1 || (gcphase == _GCmark &amp;&amp; cycle == n+2) {
		mProf_PostSweep()
	}
	releasem(mp)
}
```

## 3、GC 中 stw 时机，各个阶段是如何解决的？ （百度）


1) 在开始新的一轮 GC 周期前，需要调用 gcWaitOnMark 方法上一轮 GC 的标记结束（含扫描终止、标记、或标记终止等）。

2) 开始新的一轮 GC 周期，调用 gcStart 方法触发 GC 行为，开始扫描标记阶段。

3) 需要调用 gcWaitOnMark 方法等待，直到当前 GC 周期的扫描、标记、标记终止完成。

4) 需要调用 sweepone 方法，扫描未扫除的堆跨度，并持续扫除，保证清理完成。在等待扫除完毕前的阻塞时间，会调用 Gosched 让出。

5) 在本轮 GC 已经基本完成后，会调用 mProf_PostSweep 方法。以此记录最后一次标记终止时的堆配置文件快照。

6) 结束，释放 M。

## 4、GC 的触发时机？

初级必问，分为系统触发和主动触发。

1) gcTriggerHeap：当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发。

2) gcTriggerTime：当距离上一个 GC 周期的时间超过一定时间时，将会触发。时间周期以runtime.forcegcperiod 变量为准，默认 2 分钟。

3) gcTriggerCycle：如果没有开启 GC，则启动 GC。

4) 手动触发的 runtime.GC 方法。


# 九、内存相关

## 1、谈谈内存泄露，什么情况下内存会泄露？怎么定位排查内存泄漏问题？
答：go 中的内存泄漏一般都是 goroutine 泄漏，就是 goroutine 没有被关闭，或者没有添加超时控制，让 goroutine 一只处于阻塞状态，不能被 GC。

内存泄露有下面一些情况

1) 如果 goroutine 在执行时被阻塞而无法退出，就会导致 goroutine 的内存泄漏，一个 goroutine 的最低栈大小为 2KB，在高并发的场景下，对内存的消耗也是非常恐怖的。

2) 互斥锁未释放或者造成死锁会造成内存泄漏

3) time.Ticker 是每隔指定的时间就会向通道内写数据。作为循环触发器，必须调用 stop 方法才会停止，从而被 GC 掉，否则会一直占用内存空间。

4) 字符串的截取引发临时性的内存泄漏

```go
func main() {
	var str0 = "12345678901234567890"
	str1 := str0[:10]
}
```

5) 切片截取引起子切片内存泄漏

```go
func main() {
	var s0 = []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
	s1 := s0[:3]
}
```

6) 函数数组传参引发内存泄漏【如果我们在函数传参的时候用到了数组传参，且这个数组够大（我们假设数组大小为 100 万，64 位机上消耗的内存约为 800w 字节，即 8MB 内存），或者该函数短时间内被调用 N 次，那么可想而知，会消耗大量内存，对性能产生极大的影响，如果短时间内分配大量内存，而又来不及 GC，那么就会产生临时性的内存泄漏，对于高并发场景相当可怕。】

排查方式：

- 一般通过 pprof 是 Go 的性能分析工具，在程序运行过程中，可以记录程序的运行信息，可以是 CPU 使用情况、内存使用情况、goroutine 运行情况等，当需要性能调优或者定位 Bug 时候，这些记录的信息是相当重要。

当然你能说说具体的分析指标更加分咯，有的面试官就喜欢他问什么，你简洁的回答什么，不喜欢巴拉巴拉详细解释一通，比如虾P面试官，不过他考察的内容特别多，可能是为了节约时间。

## 2、知道 golang 的内存逃逸吗？什么情况下会发生内存逃逸？（必问）

答：
1) 本该分配到栈上的变量，跑到了堆上，这就导致了内存逃逸。
2) 栈是高地址到低地址，栈上的变量，函数结束后变量会跟着回收掉，不会有额外性能的开销。
3) 变量从栈逃逸到堆上，如果要回收掉，需要进行 gc，那么 gc 一定会带来额外的性能开销。编程语言不断优化 gc 算法，主要目的都是为了减少 gc 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。

内存逃逸的情况如下：

1) 方法内返回局部变量指针。
2) 向 channel 发送指针数据。
3) 在闭包中引用包外的值。
4) 在 slice 或 map 中存储指针。
5) 切片（扩容后）长度太大。
6) 在 interface 类型上调用方法。

## 3、请简述 Go 是如何分配内存的？

mcache mcentral mheap mspan

Go 程序启动的时候申请一大块内存，并且划分 spans，bitmap，areana 区域；arena 区域按照页划分成一个个小块，span 管理一个或者多个页，mcentral 管理多个 span 供现场申请使用；mcache 作为线程私有资源，来源于 mcentral。

这里描述的比较简单，你可以自己再去搜索下更简洁完整的答案。

## 4、Channel 分配在栈上还是堆上？哪些对象分配在堆上，哪些对象分配在栈上？

Channel 被设计用来实现协程间通信的组件，其作用域和生命周期不可能仅限于某个函数内部，所以 golang 直接将其分配在堆上

准确地说，你并不需要知道。Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。

知道变量的存储位置确实和效率编程有关系。如果可能，Golang 编译器会将函数的局部变量分配到函数栈帧（stack frame）上。然而，如果编译器不能确保变量在函数 return 之后不再被引用，编译器就会将变量分配到堆上。而且，如果一个局部变量非常大，那么它也应该被分配到堆上而不是栈上。

当前情况下，如果一个变量被取地址，那么它就有可能被分配到堆上,然而，还要对这些变量做逃逸分析，如果函数 return 之后，变量不再被引用，则将其分配到栈上。

## 5、介绍一下大对象小对象，为什么小对象多了会造成 gc 压力？

小于等于 32k 的对象就是小对象，其它都是大对象。一般小对象通过 mspan 分配内存；大对象则直接由 mheap 分配内存。通常小对象过多会导致 GC 三色法消耗过多的 CPU。优化思路是，减少对象分配。

小对象：如果申请小对象时，发现当前内存空间不存在空闲跨度时，将会需要调用 nextFree 方法获取新的可用的对象，可能会触发 GC 行为。

大对象：如果申请大于 32k 以上的大对象时，可能会触发 GC 行为。

# 十、其他问题
## 1、Go 多返回值怎么实现的？

答：Go 传参和返回值是通过 FP+offset 实现，并且存储在调用函数的栈帧中。FP 栈底寄存器，指向一个函数栈的顶部;PC 程序计数器，指向下一条执行指令;SB 指向静态数据的基指针，全局符号;SP 栈顶寄存器。

## 2、讲讲 Go 中主协程如何等待其余协程退出?

答：Go 的 sync.WaitGroup 是等待一组协程结束，sync.WaitGroup 只有 3 个方法，Add()是添加计数，Done()减去一个计数，Wait()阻塞直到所有的任务完成。Go 里面还能通过有缓冲的 channel 实现其阻塞等待一组协程结束，这个不能保证一组 goroutine 按照顺序执行，可以并发执行协程。Go 里面能通过无缓冲的 channel 实现其阻塞等待一组协程结束，这个能保证一组 goroutine 按照顺序执行，但是不能并发执行。

啰嗦一句：循环智能二面，手写代码部分时，三个协程按交替顺序打印数字，最后题目做出来了，问我代码中Add()是什么意思，我回答的不是很清晰，这家公司就没有然后了。Add()表示协程计数，可以一次Add多个，如Add(3),可以多次Add(1);然后每个子协程必须调用done（）,这样才能保证所有子协程结束，主协程才能结束。

## 3、Go 语言中不同的类型如何比较是否相等？

答：像 string，int，float interface 等可以通过 reflect.DeepEqual 和等于号进行比较，像 slice，struct，map 则一般使用 reflect.DeepEqual 来检测是否相等。

## 4、Go 中 init 函数的特征?

答：一个包下可以有多个 init 函数，每个文件也可以有多个 init 函数。多个 init 函数按照它们的文件名顺序逐个初始化。应用初始化时初始化工作的顺序是，从被导入的最深层包开始进行初始化，层层递出最后到 main 包。不管包被导入多少次，包内的 init 函数只会执行一次。应用初始化时初始化工作的顺序是，从被导入的最深层包开始进行初始化，层层递出最后到 main 包。但包级别变量的初始化先于包内 init 函数的执行。

## 5、Go 中 uintptr 和 unsafe.Pointer 的区别？

答：unsafe.Pointer 是通用指针类型，它不能参与计算，任何类型的指针都可以转化成 unsafe.Pointer，unsafe.Pointer 可以转化成任何类型的指针，uintptr 可以转换为 unsafe.Pointer，unsafe.Pointer 可以转换为 uintptr。uintptr 是指针运算的工具，但是它不能持有指针对象（意思就是它跟指针对象不能互相转换），unsafe.Pointer 是指针对象进行运算（也就是 uintptr）的桥梁。

## 6、golang共享内存（互斥锁）方法实现发送多个get请求

待补充

## 7、从数组中取一个相同大小的slice有成本吗？

或者这么问：从切片中取一个相同大小的数组有成本吗？

这是爱立信的二面题目，这个问题我至今还没搞懂，不知道从什么切入点去分析，欢迎指教。

### 深拷贝和浅拷贝

什么是深拷贝？
深拷贝（Deep Copy）是指原对象与拷贝的新对象互相独立，对其中任何一个对象的改动都不会对另外一个对象造成影响。值类型的数据默认是深拷贝，例如array、int、string、struct、float和bool类型。

什么是浅拷贝？
浅拷贝（Shallow Copy）是指将一个对象的一部分复制到另一个对象中，使用指针来引用原始对象，从而实现对原始对象的部分复制。此时新对象和老对象指向的内存地址是一样的，修改新对象值后老对象值也会变化。引用类型的数据默认是浅拷贝，例如slice和map。

要实现slice的深拷贝，就需要用到**copy方法了，copy方法返回结果为一个int值，表示从原切片复制到目的切片的长度**。在使用copy方法时，需要先初始化目的切片的长度：

- 如果 dst 长度小于 src 的长度，则 拷贝src中的部分内容；
- 如果大于，则全部拷贝过来，其余的空间填充该类型的默认值；
- 如果相等，刚好不多不少 copy 过来，所以，通常dst在初始化时即指定其为src的长度。

深拷贝是创建一个新对象，完全复制原始对象及其所有嵌套的对象，因此新的对象是原始对象的独立拷贝，之后的修改不会影响原始对象。浅拷贝则只拷贝原始对象的数据结构的地址引用，因此新的对象和原始对象的引用指向相同的底层数据结构，对新对象的修改也会影响到原始对象。













