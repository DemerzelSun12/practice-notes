[TOC]

# 一、Kubernetes

## 1.如何创建pod或者创建deployment流程？(必问)

### 一、如何创建pod流程：

1. 客户端提交创建请求，可以通过API Server的Restful API，也可以使用如何命令行工具。支持的数据类型包括JSON和YAML。
2. API Server处理用户请求，存储Pod数据到etcd。
3. 调度器通过API Server查看未绑定的Pod。尝试为Pod分配主机。
4. 过滤主机 (调度预选)：调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。
5. 主机打分(调度优选)：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。
6. 选择主机：选择打分最高的主机，进行binding操作，结果存储到etcd中。
7. kubelet根据调度结果执行Pod创建操作：绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。


### 二、如何创建deployment流程？（tips：这个要回答出创建rs的过程）

1. 准备好一个包含应用程序的Deployment的yml文件，然后通过kubectl客户端工具发送给ApiServer。
2. ApiServer接收到客户端的请求并将资源内容存储到数据库(etcd)中。
3. Controller组件(包括scheduler、replication、endpoint)监控资源变化并作出反应。
4. ReplicaSet检查数据库变化，创建期望数量的pod实例。
5. Scheduler再次检查数据库变化，发现尚未被分配到具体执行节点(node)的Pod，然后根据一组相关规则将pod分配到可以运行它们的节点上，并更新数据库，记录pod分配情况。
6. Kubelete监控数据库变化，管理后续pod的生命周期，发现被分配到它所在的节点上运行的那些pod。如果找到新pod，则会在该节点上运行这个新pod。
7. kuber proxy运行在集群各个主机上，管理网络通信，如服务发现、负载均衡。例如当有数据发送到主机时，将其路由到正确的pod或容器。对于从主机上发出的数据，它可以基于请求地址发现远程服务器，并将数据正确路由，在某些情况下会使用轮训调度算法(Round-robin)将请求发送到集群中的多个实例。
8. kubectl提交一个请求，来创建RC，此时Controller Manager通过API server里的接口监听到这个RC事件，分析之后，发现当前集群中还没有它对应的Pod实例，于是根据RC里的Pod模板定义Pod对象；接下来，此事件被Scheduler发现，它立即执行一个复杂的调度流程，为这个新Pod选定一个落户的Node，这个过程可称为绑定；随后模板Node上运行的Kubelet进程通过API Server监测到这个“新生的”Pod并按照它的定义，启动Pod并负责后期的管理；随后我们通过Kubectl提交一个映射到该Pod的Server的创建请求，Controller Manager会通过Label标签查询到相关联的Pod实例，然后生成Service的Endpoints信息；接下来，所有Node上运行的Proxy进程通过API Server查询并监听Service对象及其对应的Endpoints信息，建立一个负载均衡器来实现Service访问到后端Pod的流量转发功能；

## 2. k8s中pod之间是怎么通信的？

1. 同一个Pod内的多个容器之间：lo（通过localhost回环地址通信）。
2. 各Pod之间的通讯：overlay Network （覆盖网络）。
3. Pod与 Service之间的通讯：（使用各节点的 Iptables规则）。

## 3. k8s中的pod中OOM机制有了解过吗，原理是什么？

（tips：蚂蚁金服的oceanbase数据库产品问了这个问题，当时被问还是有点点蒙的。这个涉及到pod的QOS的相关知识。阿里面试官首先介绍了系统中进程的OOM机制，会给每个进程进行打分，然后kill掉得分最高的那一个进程，然后问pod的OOM是怎么样的？）

答：当系统 OOM上时，对于处理不同 OOMScore 的进程表现不同，OOMScore 是针对 memory 的，当宿主上 memory 不足时系统会优先 kill 掉 OOMScore 值高的进程，可以使用如下指令：
```bash
  $ cat /proc/$PID/oom_score
```
查看进程的 OOMScore。OOMScore 的取值范围为 [-1000, 1000]，Guaranteed pod 的默认值为 -998，Burstable pod 的值为 2~999，BestEffort pod 的值为 1000，也就是说当系统 OOM 时，首先会 kill 掉 BestEffort pod 的进程，若系统依然处于 OOM 状态，然后才会 kill 掉  Burstable pod，最后是 Guaranteed pod；

## 4. k8s的基本组件及其作用？
一个kubernetes集群主要是由控制节点(master)、工作节点(node)构成，每个节点上都会安装不同的组件。

- master：集群的控制平面，负责集群的决策 ( 管理 )。

  - ApiServer :资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制。

  - Scheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上。

  - ControllerManager :负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等。

  - Etcd ：负责存储集群中各种资源对象的信息，k/v方式存储，所有的 k8s 集群数据存放在此。

  - Kuberctl: 命令行配置工具。

- node：集群的数据平面，负责为容器提供运行环境 ( 干活 )。

  - Kubelet :负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器，会按固定频率检查节点健康状态并上报给 APIServer，该状态会记录在 Node 对象的 status 中。

  - KubeProxy :负责提供集群内部的服务发现和负载均衡。

  - Docker :负责节点上容器的各种操作。

## 5.kubevirt的基本组件及其作用？
- virt-api：kubevirt是以CRD形式去管理VM Pod，virt-api就是所有虚拟化操作的入口，这里面包括常规的CDR更新验证、以及console、vm start、stop等操作。

- virt-controller：virt-controller会根据vmi CRD，生成对应的virt-launcher Pod，并且维护CRD的状态。与kubernetes api-server通讯监控VMI资源的创建删除等状态。

- virt-handler：virt-handler会以deamonset形式部署在每一个节点上，负责监控节点上的每个虚拟机实例状态变化，一旦检测到状态的变化，会进行响应并且确保相应的操作能够达到所需（理想）的状态。virt-handler还会保持集群级别VMI Spec与相应libvirt域之间的同步；报告libvirt域状态和集群Spec的变化；调用以节点为中心的插件以满足VMI Spec定义的网络和存储要求。

- virt-launcher：每个virt-launcher，pod对应着一个VMI，kubelet只负责virt-launcher pod运行状态，不会去关心VMI创建情况。virt-handler会根据CRD参数配置去通知virt-launcher去使用本地的libvirtd实例来启动VMI，随着Pod的生命周期结束，virt-lanuncher也会去通知VMI去执行终止操作；其次在每个virt-launcher pod中还对应着一个libvirtd，virt-launcher通过libvirtd去管理VM的生命周期，这样做到去中心化，不再是以前的虚拟机那套做法，一个libvirtd去管理多个VM。

- virtctl：virtctl是kubevirt自带类似kubectl的命令行工具，它是越过virt-launcher pod这一层去直接管理VM虚拟机，可以控制VM的start、stop、restart。

## 6.Etcd的写数据流程是什么？

- 总体上的请求流程从上至下依次为客户端 → API 接口层 → etcd Server → etcd raft 算法库。）
- 读请求：客户端通过负载均衡选择一个 etcd 节点发出读请求，API 接口层提供了 Range RPC 方法，etcd 服务端拦截到 gRPC 读请求后，调用相应的处理器处理请求。
- 写请求：客户端通过负载均衡选择一个 etcd 节点发起写请求，etcd 服务端拦截到 gRPC 写请求，涉及一些校验和监控，之后 KVServer 向 raft 模块发起提案，内容即为写入数据的命令。经过网络转发，当集群中的多数节点达成一致并持久化数据后，状态变更且 MVCC 模块执行提案内容。


## 7.在异构架构下，比如有些主机是x86，有些主机是arm架构，k8s怎么保证异构架构下这些主机拉起不同的架构的镜像？

docker每一个镜像包含了一个文件，这个文件包含了有关于镜像信息，如层、大小和摘要。docker manifest命令还向用户提供附加信息，比如构建镜像的操作系统和体系结构。而manifest list是一个镜像清单列表，用于存放多个不同os/arch的镜像信息。我们主要用到manifest的目的，其实还是多用于存放不同的os/arch信息，也就是方便我们在不同的CPU架构（arm或者x86）或者操作系统中，通过一个镜像名称拉取对应架构或者操作系统的镜像，这个尤其是在K8S中，对于异构CPU的服务器中的镜像显得尤为有效。

## 8. 如何理解容器的虚拟化技术

虚拟化技术**通过Hypervisor实现VM与底层硬件的解耦**。而容器（container）技术是一种更加轻量级的操作系统虚拟化技术，**将应用程序及其运行依赖环境打包封装到标准化、强移植的镜像中，通过容器引擎提供进程隔离、资源可限制的运行环境，实现应用与OS平台及底层硬件的解耦**，一次打包，随处运行。容器基于镜像运行，可部署在物理机或虚拟机上，通过容器引擎与容器编排调度平台实现容器化应用的生命周期管理。

## 9. 命名空间和控制组是什么

两个核心概念：命名空间（Namespace）和控制组（Cgroup）。

### 命名空间（Namespace）
命名空间是Linux内核提供的一种机制，用于**将全局系统资源隔离成一个个独立的空间**。每个命名空间都**有自己的进程、网络、文件系统等资源**。这意味着不同的命名空间可以相互隔离，使得不同的进程或容器运行在不同的环境中。这种隔离性确保了容器内的应用程序只能看到和访问它所属的特定命名空间，从而实现了资源隔离。
命名空间为容器技术提供了以下功能：

- 进程隔离：每个容器都有自己的进程空间，进程之间相互隔离。
- 网络隔离：每个容器都有自己的网络栈，可以独立地配置网络设置。
- 文件系统隔离：每个容器都有自己的文件系统挂载点，确保文件系统的独立性。

### 控制组（Cgroup）

控制组是Linux内核提供的另一种机制，用于**对进程或进程组进行资源限制、优先级控制和统计等操作**。通过控制组，可以将一组进程或容器的资源使用情况限制在一个范围内，从而实现资源的有效管理和隔离。
控制组为容器技术提供了以下功能：
- 资源限制：可以限制容器的CPU、内存等资源的使用量。
- 优先级管理：根据需要调整容器的CPU和内存使用优先级。
- 统计和分析：收集和分析容器的资源使用数据，便于监控和优化。



# 二、redis

## 1. redis数据结构有哪些？

Redis 提供了丰富的数据类型，常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。** 随着 Redis 版本的更新，后面又支持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。

1. String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。
2. List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。                     
3. Hash 类型：缓存对象、购物车等。
4. Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
5. Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

## 2. 用什么结构实现延迟消息队列？

延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：
1. 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
2. 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
3. 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。


## 3. redis分片集群，如何分片的，有什么好处？

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 Redis 切片集群（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。

在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：
1. 根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
2. 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽

也就是：CRC16(key1)%16384，就能得到 key 对应的哈希槽编号，然后在通过编号找到对应的节点。


# 三、Docker

## 1. 解释Docker镜像的构成与原理。

### Docker镜像的构成与原理

Docker镜像是⽤于构建Docker容器的模板，它包含了应⽤程序运⾏所需的所有内容，包括⽂件系统、库、运⾏环境和配置参数。Docker镜像是⼀个只读的模板，它可以由Docker容器启动并运⾏。Docker镜像由多个层组成，每个层包含了⽂件系统的⼀部分。这些层通过联合⽂件系统(UnionFS)进⾏组合，形成了⼀个完整的⽂件系统视图。

### Docker镜像的构成

1.	基础镜像层：Docker镜像是通过多个只读层进⾏构建的，其中基础镜像层是最底层的只读层，它包含了操作系统的核⼼组件和基本系统⼯具。
2.	中间镜像层：在基础镜像层之上，可以有多个中间镜像层，每个中间镜像层都代表了⼀个修改，例如安装软件包、更新配置等。
3.	顶层镜像层：顶层镜像层是最上层的只读层，它包含了运⾏时环境和应⽤程序本⾝，以及相关的配置参数。

### Docker镜像的原理

Docker镜像的构建原理是通过分层的⽅式实现的。每个镜像层都是只读的，⽽容器运⾏时则可以在这些只读层的基础上创建⼀个可写层，⽤于存储容器内部的修改和数据。

## 2. Docker容器的⽹络模式，及其与宿主机⽹络的关系。

### Docker容器的⽹络模式
1.	桥接模式：在桥接模式下，容器与宿主机在相同的⼦⽹内，容器之间可相互通信，宿主机也可以与容器通信。桥接模式是默认的⽹络模式。
2.	主机模式：在主机模式下，容器与宿主机共享⽹络命名空间，容器使⽤宿主机的⽹络栈，可以直接访问宿主机的⽹络接⼜。因此，容器的⽹络性能会受到宿主机⽹络负载的影响。
3.	⽆⽹络模式：在⽆⽹络模式下，容器没有独⽴的⽹络命名空间，它与宿主机完全隔离，⽆法进⾏⽹络通信。
4.	⾃定义⽹络模式：在⾃定义⽹络模式下，⽤户可以创建⾃定义的⽹络，容器可以连接到该⽹络并与其他容器相互通信，达到更灵活的⽹络配置。

### 与宿主机⽹络的关系

Docker容器的⽹络模式决定了容器内部与外部⽹络的连接⽅式。不同的⽹络模式会影哨容器与宿主机⽹络的关系。在桥接模式下，容器获取宿主机IP的⼀个⼦IP，在主机模式下，容器使⽤宿主机的⽹络栈，与宿主机的⽹络连接更加紧密，⽆⽹络模式下，容器与宿主机完全隔离。

## 3. 常用命令

### Dockerfile的基本结构和常⽤指令

Dockerfile是⽤于构建Docker镜像的⽂本⽂件，其中包含了⽤于配置和构建镜像的指令和参数。Dockerfile通常包含以下基本结构和常⽤指令：

FROM
指定基础镜像，可以是⼀个操作系统镜像或其他已有镜像。
```dockerfile
FROM	ubuntu:latest
```
RUN
在镜像中执⾏命令，安装软件包、更新系统等。
```dockerfile
RUN	apt-get	update	&&	apt-get	install	-y	python3
```

COPY
将⽂件从主机复制到镜像的⽂件系统中。
```dockerfile
COPY	app.py	/usr/src/app/
```
CMD
设置容器启动时执⾏的命令，默认只有最后⼀个CMD指令会⽣效。
```dockerfile
CMD	["python3",	"app.py"]
```
WORKDIR
WORKDIR指令⽤于指定容器内部的⼯作⽬录，并且可以在Dockerfile中多次使⽤以改变⼯作⽬录。
```dockerfile
FROM	ubuntu
WORKDIR	/app
```

ENV
可以通过使⽤ENV指令来定义和使⽤环境变量
```dockerfile
ENV	APP_ENV	${ENVIRONMENT}
```

### 描述Dockerfile中的CMD指令和ENTRYPOINT指令的区别。

CMD指令

CMD指令⽤于指定容器启动时要执⾏的默认命令，当Docker容器启动时，如果没有指定其他的命令，CMD指定的命令将被执⾏。可以在Dockerfile中多次使⽤CMD指令，但只有最后⼀个CMD指令会⽣效。
```dockerfile
FROM	alpine
CMD	["echo",	"Hello,	World!"]
```
ENTRYPOINT指令
ENTRYPOINT指令⽤于指定容器启动时要执⾏的默认命令，与CMD不同的是，**ENTRYPOINT指令指定的命令不会被覆盖，⽽是会作为命令的前缀，可以通过CMD指定附加的参数。**

```dockerfile
FROM	alpine
ENTRYPOINT	["echo",	"Hello"]
CMD	["World!"]
```



## 4. 解释Docker镜像与Docker容器之间的关系。

Docker镜像是Docker容器的基础。镜像是⼀个只读的模板，包含了运⾏容器所需的⽂件系统、环境变量、程序和库等。当我们创建⼀个容器时，实际上是在镜像的基础上启动了⼀个可写的容器层。
在Docker中，我们可以通过镜像来创建容器，**⼀个镜像可以同时启动多个容器实例**。每个容器都是镜像的⼀个运⾏实例，拥有⾃⼰的⽂件系统、⽹络配置和进程空间。

## 5. 解释Docker中的数据卷（Volume）是什么，以及它的作用是什么？
数据卷（Volume）在Docker中是⼀种持久化存储机制，⽤于在容器之间共享数据和保存持久化数据。数据卷可以在容器之间共享和传递数据，同时还可以在容器被删除后保留数据。数据卷的作⽤包括：
1.	允许容器之间共享数据：数据卷可以被多个容器挂载和共享，从⽽实现容器之间的数据共享。
2.	保存持久化数据：数据卷中的数据可以在容器被删除后保留，因此适合存储需要持久化的数据。
3.	扩展性和灵活性：数据卷可以在不同的容器之间传递和共享数据，从⽽增强了容器的扩展性和灵
活性。

创建⼀个数据卷，并将其挂载到容器中，从⽽实现容器之间的数据共享和持久化存储。

```bash
#创建数据卷
$ docker	volume create my_volume
#运⾏容器，并将数据卷挂载到容器中
$ docker run -d --name my_container -v my_volume:/data my_image
```

## 6. 持续集成/持续部署（CI/CD）

### 6.1 多容器应⽤的持续集成和持续部署（CI/CD）如何实现

在多容器应⽤的持续集成和持续部署中，可以使⽤Docker和Kubernetes来实现整个流程。

1. 首先，将应⽤代码和Dockerfile提交到版本控制系统，如GitHub。随后，通过持续集成⼯具如Jenkins或GitLab	CI，对代码进⾏构建、测试和打包成Docker镜像。
2. 然后，将镜像推送到镜像仓库，如Docker	Hub或私有镜像仓库。
3. 接下来，通过持续部署⼯具如Argo	CD或Flux，将Kubernetes配置⽂件提交到版本控制系统，并⾃动应⽤到Kubernetes集群中。
4. 最后，Kubernetes根据配置⽂件，⾃动创建、更新和删除应⽤实例，实现持续部署。

### 示例

在基于	Docker	的持续集成与持续部署⽅案中，可以选择以下⼯具：
- 持续集成⼯具：	Jenkins、GitLab	CI、Travis	CI
- 持续部署⼯具：	Kubernetes、Docker	Swarm、Spinnaker

流程设计
1.	代码管理：	开发⼈员将代码提交⾄版本控制系统（如Git）。
2.	持续集成：	持续集成⼯具检测到代码提交后，⾃动触发构建、测试和打包流程。
3.	镜像构建：	使⽤Dockerfile构建Docker镜像，包含应⽤程序和其运⾏时环境。
4.	镜像发布：	将构建好的Docker镜像上传⾄镜像仓库（如Docker	Hub）。
5.	持续部署：	使⽤持续部署⼯具进⾏部署和管理应⽤。

示例：
- 微服务架构：	利用Docker容器部署和管理微服务，实现高度可伸缩和灵活的部署。
- ⾃动化测试：	集成自动化测试，保证每次构建的代码质量。
- 版本控制：	使⽤版本控制系统管理Dockerfile和部署配置，确保可追溯的部署历史。
- 持续监控：	集成监控⼯具，实现对应⽤运⾏状态的实时监控。


## 7. Docker镜像的底层原理是什么？请详细解释。

1. Docker	镜像的底层原理是**基于容器的联合⽂件系统**。**Docker	镜像是只读的**，由⼀系列⽂件系统层叠加⽽成。**当⼀个容器启动时，⼀个新的可写层会被添加到⽂件系统的顶部，⽤于容器运⾏时的⽂件操作。**
2. 每⼀层都包含⽂件或⽬录的更改，使得创建、修改和删除的操作更加⾼效。这种联合⽂件系统的原理使得	Docker镜像的构建和管理更加灵活和⾼效。
3. 举例来说，⼀个基于	Ubuntu	镜像的	Docker	镜像，在⽂件系统底层可能包含	Ubuntu	的基础⽂件系统，⽽顶层则可能添加了⼀些⾃定义的应⽤程序和配置⽂件。这样，就可以构建出不同⽤途的镜像，⽽且它们可以共享相同的基础层，节省了存储空间和⽹络带宽

### 7.1 在	Docker	镜像中，分层存储是如何实现的？

在Docker镜像中，分层存储是通过AUFS（Advanced	Multi-Layered	Unification	File	System）实现的。AUFS是⼀种联合⽂件系统，**允许将多个⽬录合并成⼀个单⼀⽬录，同时保留各⽬录的独⽴性。**当创建Docker镜像时，每个指令都会在现有基础镜像的基础上创建⼀个新的层，这些层以只读的⽅式堆叠在⼀起，形成完整的镜像。这种分层存储的设计使得Docker镜像可以⾼效地共享基础层，并且在构建镜像时只需构建更改的部分，从⽽减少了资源占⽤和构建时间。

## 8. 快速部署与检查

使用多阶段构建的方法

使⽤多阶段构建：利⽤多阶段构建可以减少镜像中不必要的依赖和⽂件，最终只保留运⾏应⽤所需的最⼩⽂件。

```dockerfile
#	第⼀阶段
FROM	golang:1.16	as	builder
WORKDIR	/app
COPY	.	.
RUN	go	build	-o	myapp

#	第⼆阶段
FROM	alpine:latest
WORKDIR	/app
COPY	--from=builder	/app/myapp	.
CMD	["./myapp"]
```

### 8.1 使⽤Dockerfile构建镜像时，你如何在不同的构建阶段共享⽂件和⽬录？

使⽤Dockerfile构建镜像时，在不同的构建阶段可以**通过临时容器将⽂件和⽬录进⾏共享**。可以使⽤CO PY指令将需要共享的⽂件复制到中间镜像。然后**在下⼀个阶段使⽤--from=<stage-name>参数来引⽤之前阶段的中间镜像。**


